{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00001-10528e06-f6bc-4d22-87ba-44ee389423e2",
        "deepnote_cell_height": 513.59375,
        "deepnote_cell_type": "markdown",
        "id": "CzR6cZvYkyl6"
      },
      "source": [
        "## Assignment 2\n",
        "**Submission deadlines:**\n",
        "**Submission deadlines:**\n",
        "- get at least **4** points by lab session (week 24-28.03.2025)\n",
        "- remaining points: by lab session (week 31.03-04.04.2025)\n",
        "\n",
        "**Points:** Aim to get 16 out of 18+ possible points\n",
        "\n",
        "## Submission instructions\n",
        "The class is held on-site in lab rooms. Please prepare you notebook on your computer or anywhere in the cloud (try using DeepNote or Google Colab).\n",
        "\n",
        "Make sure you know all the questions and answers, and that the notebook contains results; before presentation do `Runtime -> Restart and run all`\n",
        "\n",
        "![Alt text](data:image/png;base64,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)\n",
        "\n",
        "We provide starter code, however you are not required to use it as long as you properly solve the tasks.\n",
        "\n",
        "## Extra points\n",
        "\n",
        "You can earn extra 2 points if all your experiments are logged with [Weights and Biases](http://wandb.ai)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00002-c9d8b5e1-13d2-492d-9ad6-d82d4419394b",
        "deepnote_cell_height": 82,
        "deepnote_cell_type": "markdown",
        "id": "eJ7DqCH7NDlC"
      },
      "source": [
        "# Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00003-48229273-726d-45db-bb12-068773ea6b9c",
        "deepnote_cell_height": 433.421875,
        "deepnote_cell_type": "markdown",
        "id": "YXr1RwyMFITD"
      },
      "source": [
        "\n",
        "## Problem 1 [2p]:\n",
        "\n",
        "Let's see why GPUs are useful in deep learning. Compare matrix multiplication speed for a few matrix shapes when implemented:\n",
        "1. as loops in Python\n",
        "2. using np.einsum\n",
        "3. using numpy on CPU\n",
        "4. using pytorch on CPU\n",
        "5. using pytorch on GPU\n",
        "\n",
        "Finally, consider two square matrices, $A$ and $B$. We have 4 possibilities of multiplying them or their transpositions:\n",
        "1. $AB$\n",
        "2. $A^TB$\n",
        "3. $AB^T$\n",
        "4. $A^TB^T$\n",
        "\n",
        "Which option is the fastest? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00004-6fcf24af-39f5-4e54-a68e-21493b4f3484",
        "deepnote_cell_height": 313.1875,
        "deepnote_cell_type": "markdown",
        "id": "eQa69LGTaiym"
      },
      "source": [
        "## Problem 2: Stochastic Gradient Descent (training MNIST digits) [2p]\n",
        "\n",
        "We provide below starter code that trains a classification model (with softmat + cross entropy loss). Alternatively, implement your own training loop and use it to solve this problem jointly with the next one.\n",
        "\n",
        "Implement the following additions to the SGD code provided:\n",
        "  1. **[1p]** momentum\n",
        "  2. **[0.5p]** learning rate schedule\n",
        "  3. **[0.5p]** weight decay, in which we additionally minimize for each weight matrix (but typically not the bias) the sum of its elements squared. One way to implement it is to use the function `model.named_parameters` and select all parameters whose names contain \"`weight`\" rather than \"`bias`\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00005-08ef04aa-9e94-4455-bddc-b843562afd3f",
        "deepnote_cell_height": 350,
        "deepnote_cell_type": "markdown",
        "id": "YsLt4dGsaosv"
      },
      "source": [
        "## Problem 3: Tuning the Network for MNIST [2p]\n",
        "\n",
        "Tune the following network to reach **validation error rate below 1.9%**.\n",
        "This should result in a **test error rate below 2%**. To\n",
        "tune the network you will need to:\n",
        "1. Choose the number of layers (more than 1, less than 5);\n",
        "2. Choose the number of neurons in each layer (more than 100,\n",
        "    less than 5000);\n",
        "3. Pick proper weight initialization;\n",
        "4. Pick proper learning rate schedule (need to decay over time,\n",
        "    a good range to check on MNIST is about 1e-2 ... 1e-1 at the beginning and\n",
        "    half of that after 10000 batches);\n",
        "5. Pick a momentum constant (probably a constant one will be OK).\n",
        "\n",
        "\n",
        "Please note: there are many hyperparameter settings that give the desired answer, some may require tuning all hyperparameters, some only a few."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00006-1469d97b-d10e-428a-a29a-f6446ffaa579",
        "deepnote_cell_height": 130.796875,
        "deepnote_cell_type": "markdown",
        "id": "YrUQloaln1UA"
      },
      "source": [
        "## Problem 4*: Convolutional Network [2p]\n",
        "\n",
        "Use convolutional and max-pooling layers (`Conv2d`, `Max_pool2d` or their functional variants) and (without dropout) get a test error rate below 1.5%.\n",
        "\n",
        "Hint: see [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d), [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d), [F.relu](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00008-b71ece13-36f1-4661-b0c6-3739ba0af279",
        "deepnote_cell_height": 212,
        "deepnote_cell_type": "markdown",
        "id": "mB3T_HuYawyQ"
      },
      "source": [
        "## Problem 5: Data Augmentation [1p]\n",
        "\n",
        "Apply data augmentation methods (e.g. rotations, noise, crops) when training networks on MNIST, to significantly reduce test error rate for your network. You can use functions from the [torchvision.transforms](http://pytorch.org/docs/master/torchvision/transforms.html) module.\n",
        "\n",
        "Please note: when using random transformations during training, make sure they are re-computed in every epoch. Consider applying augmentation either in the training loop or in the `InMemDataLoader`. For the second case, function `InMemDataLoader.__iter__` is a good place to do it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak-ti9iICQki"
      },
      "source": [
        "\n",
        "## Problem 6: Dropout [2p]\n",
        "\n",
        "Learn about dropout:\n",
        "\n",
        "- implement a **dropout** layer\n",
        "- or use `nn.Dropout` (then the exercise is worth 1.5 points)\n",
        "\n",
        "and try to train a\n",
        "network getting below 1.5% test error rates with dropout, but no convolutions, or below 1% when dropout is used jointly with convolutions!\n",
        "\n",
        "Remember to turn off dropout during testing, using `model.train()` and `model.eval()`!\n",
        "\n",
        "Hint: Use [torch.nn.functional.dropout](http://pytorch.org/docs/master/nn.html#torch.nn.functional.dropout).\n",
        "\n",
        "Details: http://arxiv.org/pdf/1207.0580.pdf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00009-9efae45c-dfcb-4687-b7c4-98b007244266",
        "deepnote_cell_height": 226,
        "deepnote_cell_type": "markdown",
        "id": "Af7itFE7a0eY"
      },
      "source": [
        "## Problem 7: Batch Normalization [2p]\n",
        "\n",
        "[Batch Normalization](https://arxiv.org/abs/1502.03167) helps training neural networks because it [normalizes layer activation magnitudes](https://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization.pdf). It typically allows to train networks faster and/or with higher learning rates, lessens the importance\n",
        "of initialization and might eliminate the need for Dropout.\n",
        "\n",
        "Implement Batch Normalization and compare with regular training of MNIST models.\n",
        "\n",
        "Remember to use the batch statistics during model training and to use an average of training batch statistics during model evaluation. For details please consult the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00010-82d7197f-70be-49e8-8a59-99ea637bf693",
        "deepnote_cell_height": 212,
        "deepnote_cell_type": "markdown",
        "id": "CD1Ke8R4a1-Q"
      },
      "source": [
        "## Problem 8: Norm Constraints [1p]\n",
        "\n",
        "Implement norm constraints, i.e. instead of weight decay, that tries to set all weights to small values, apply a limit on the total\n",
        "norm of connections incoming to a neuron. In our case, this\n",
        "corresponds to clipping the norm of *rows* of weight\n",
        "matrices. An easy way of implementing it is to make a gradient\n",
        "step, then look at the norm of rows and scale down those that are\n",
        "over the threshold (this technique is called \"projected gradient descent\").\n",
        "\n",
        "Please consult the Dropout paper (http://arxiv.org/pdf/1207.0580.pdf) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00012-9ad9a7b8-4ee0-4df2-8a0c-6ed0cb246cdc",
        "deepnote_cell_height": 198,
        "deepnote_cell_type": "markdown",
        "id": "w7LoH9DIa88J"
      },
      "source": [
        "## Problem 9: Hyperparameter tuner [2p]\n",
        "\n",
        "Implement a hyper-parameter tuner able to optimize the learning rate schedule, number of neurons, and similar hyperparameters. To start, use a random search (please see http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf and especially Fig 1. for intuitions on why random search is better than grid search). It may be a good idea to use a fixed maximum number of epochs (or training time) for each optimization trial to prevent selecting hyperparameters that yield slowly converging solutions. A good result will be a set of hyperparameters that reach on MNIST solutions with test errors less than $1.3\\%$ in no more than 50 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00013-1bb7d06a-33a4-4e1a-9922-d09becbcbddb",
        "deepnote_cell_height": 464.390625,
        "deepnote_cell_type": "markdown",
        "id": "mzJTDu2aE8sk"
      },
      "source": [
        "## Problem 10: Pruning [1p]\n",
        "\n",
        "Prune the MNIST network to retain validation accuracy no worse than 0.1 percentage point at maximum sparsity (maximal number of weights removed from the network).\n",
        "\n",
        "One way to do it is to\n",
        "1. train the network,\n",
        "2. set to zero the smallest weights (typically you can zero up to 50% of weights)\n",
        "3. retrain the network, keeping the zeroed weights zeroed, and repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00015-f8cf66c4-94bb-492c-abb5-845f0be43678",
        "deepnote_cell_height": 130.796875,
        "deepnote_cell_type": "markdown",
        "id": "aotfN2N2FCM6"
      },
      "source": [
        "## Problem 11: Other tricks [1p-many]\n",
        "\n",
        "The neural network literature is full of tricks for training neural networks. Find some and implement them. Please note: the number of points depends on the hardness of the extension you want to implement. If in doubt, consult the TA beforehand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00016-c2f60d20-e061-443c-a8e3-1713b5192445",
        "deepnote_cell_height": 120.390625,
        "deepnote_cell_type": "markdown",
        "id": "NNfw6pY9sRJe"
      },
      "source": [
        "# Starter code\n",
        "\n",
        "The code below trains a SoftMax regression model in PyTorch. It can easily be extended into a full multilayer neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00017-cf2d5c0e-2979-4394-9d7b-26cf2d6f6225",
        "deepnote_cell_height": 66,
        "deepnote_cell_type": "code",
        "id": "iEUPZksWm9YU",
        "ExecuteTime": {
          "end_time": "2025-03-25T15:23:49.799399300Z",
          "start_time": "2025-03-25T15:23:49.640804600Z"
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00018-a007af69-e00b-42a8-8ccd-13a9d5d9f6a5",
        "deepnote_cell_height": 264,
        "deepnote_cell_type": "code",
        "id": "039umgT_lsH2",
        "ExecuteTime": {
          "end_time": "2025-03-25T15:23:49.864126500Z",
          "start_time": "2025-03-25T15:23:49.796435100Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-25T15:23:49.880118100Z",
          "start_time": "2025-03-25T15:23:49.821117400Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jKtVBTLCQkk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743781937403,
          "user_tz": -120,
          "elapsed": 15,
          "user": {
            "displayName": "Mateusz Budzyński",
            "userId": "05911681996609353404"
          }
        },
        "outputId": "99aa1b2f-741c-471d-a17f-ca1ccacfd1bd"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00019-ef919890-5be1-4bbd-9b4b-3bfb1aefee40",
        "deepnote_cell_height": 732,
        "deepnote_cell_type": "code",
        "id": "tPOMFqLZsfuj",
        "ExecuteTime": {
          "end_time": "2025-03-25T15:24:30.261639600Z",
          "start_time": "2025-03-25T15:24:30.168813600Z"
        }
      },
      "outputs": [],
      "source": [
        "def compute_error_rate(model, data_loader, device=\"cpu\"):\n",
        "    \"\"\"Evaluate model on all samples from the data loader.\n",
        "    \"\"\"\n",
        "    # Put the model in eval mode, and move to the evaluation device.\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    if isinstance(data_loader, InMemDataLoader):\n",
        "        data_loader.to(device)\n",
        "\n",
        "    num_errs = 0.0\n",
        "    num_examples = 0\n",
        "    # we don't need gradient during eval!\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            outputs = model.forward(x)\n",
        "            _, predictions = outputs.data.max(dim=1)\n",
        "            num_errs += (predictions != y.data).sum().item()\n",
        "            num_examples += x.size(0)\n",
        "    return num_errs / num_examples\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "    \"\"\"Helper to plot the trainig progress over time.\"\"\"\n",
        "    plt.figure(figsize=(16, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    train_loss = np.array(history[\"train_losses\"])\n",
        "    plt.semilogy(np.arange(train_loss.shape[0]), train_loss, label=\"batch train loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    train_errs = np.array(history[\"train_errs\"])\n",
        "    plt.plot(np.arange(train_errs.shape[0]), train_errs, label=\"batch train error rate\")\n",
        "    val_errs = np.array(history[\"val_errs\"])\n",
        "    plt.plot(val_errs[:, 0], val_errs[:, 1], label=\"validation error rate\", color=\"r\")\n",
        "    plt.ylim(0, 0.20)\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00020-12705b84-2e28-4596-878c-69510f5bf058",
        "deepnote_cell_height": 130.796875,
        "deepnote_cell_type": "markdown",
        "id": "OT6R09JnnYs9"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "Training speed is important. By default, data is loaded on the CPU, then shipped in batches to the GPU. For this exercise, we will load the full dataset onto the GPU, which speeds up training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00021-b3c4901d-b2c9-400d-84d3-667224735d7d",
        "deepnote_cell_height": 1362,
        "deepnote_cell_type": "code",
        "id": "OPh9uR8ZorL7",
        "ExecuteTime": {
          "end_time": "2025-03-25T15:24:30.262631500Z",
          "start_time": "2025-03-25T15:24:30.200818300Z"
        }
      },
      "outputs": [],
      "source": [
        "class InMemDataLoader(object):\n",
        "    \"\"\"\n",
        "    A data loader that keeps all data in CPU or GPU memory.\n",
        "    \"\"\"\n",
        "\n",
        "    __initialized = False\n",
        "\n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False,sampler=None,\n",
        "        batch_sampler=None, drop_last=False, transform=None):\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
        "        batches = []\n",
        "        for i in tqdm(range(len(dataset))):\n",
        "            batch = [torch.tensor(t) for t in dataset[i]]\n",
        "            batches.append(batch)\n",
        "        tensors = [torch.stack(ts) for ts in zip(*batches)]\n",
        "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "        if batch_sampler is not None:\n",
        "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
        "                raise ValueError(\n",
        "                    \"batch_sampler option is mutually exclusive \"\n",
        "                    \"with batch_size, shuffle, sampler, and \"\n",
        "                    \"drop_last\"\n",
        "                )\n",
        "            self.batch_size = None\n",
        "            self.drop_last = None\n",
        "\n",
        "        if sampler is not None and shuffle:\n",
        "            raise ValueError(\"sampler option is mutually exclusive with \" \"shuffle\")\n",
        "\n",
        "        if batch_sampler is None:\n",
        "            if sampler is None:\n",
        "                if shuffle:\n",
        "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
        "                else:\n",
        "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
        "            batch_sampler = torch.utils.data.BatchSampler(\n",
        "                sampler, batch_size, drop_last\n",
        "            )\n",
        "\n",
        "        self.sampler = sampler\n",
        "        self.batch_sampler = batch_sampler\n",
        "        self.__initialized = True\n",
        "\n",
        "    def __setattr__(self, attr, val):\n",
        "        if self.__initialized and attr in (\"batch_size\", \"sampler\", \"drop_last\"):\n",
        "            raise ValueError(\n",
        "                \"{} attribute should not be set after {} is \"\n",
        "                \"initialized\".format(attr, self.__class__.__name__)\n",
        "            )\n",
        "\n",
        "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch_indices in self.batch_sampler:\n",
        "            batch = self.dataset[batch_indices]\n",
        "\n",
        "            if self.transform:\n",
        "                inputs, targets = batch  # Zakładamy, że batch = (X, y)\n",
        "                inputs = self.transform(inputs)  # Transformujemy tylko obrazy\n",
        "                batch = (inputs, targets)\n",
        "\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_sampler)\n",
        "\n",
        "    def to(self, device):\n",
        "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
        "        return self"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00022-781fa74f-113b-42aa-abad-f98814527964",
        "deepnote_cell_height": 390,
        "deepnote_cell_type": "code",
        "id": "d4RuDI9YpPhe"
      },
      "source": [
        "```python\n",
        "# Monkey-patch MNIST to use a more robust MNIST mirror\n",
        "torchvision.datasets.MNIST.resources = [\n",
        "    (\n",
        "        \"https://web.archive.org/web/20150906081542/http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\",\n",
        "        \"f68b3c2dcbeaaa9fbdd348bbdeb94873\",\n",
        "    ),\n",
        "    (\n",
        "        \"https://web.archive.org/web/20150906081542/http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\",\n",
        "        \"d53e105ee54ea40749a09fcbcd1e9432\",\n",
        "    ),\n",
        "    (\n",
        "        \"https://web.archive.org/web/20150906081542/http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\",\n",
        "        \"9fb629c4189551a2d022fa330f9573f3\",\n",
        "    ),\n",
        "    (\n",
        "        \"https://web.archive.org/web/20150906081542/http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\",\n",
        "        \"ec29112dd5afa0611ce80d1b7f02629c\",\n",
        "    ),\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00023-1ae08eac-ed89-46d5-b212-29029275d401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "c67ad8b206004340992321304d25b6c8",
            "281b62a53cf645d69255193cb5197bb9",
            "32451a143aae45e69efa7fae9f8b78b3",
            "48c7890b420a4ea1820087025444cff1",
            "ded02dcef1894d36877d622e85bf2326",
            "d2c9394e779440498f7026425842b4d4",
            "6020a17ca8c142b48f1e6131e4b6592d",
            "92c54e5228144e8f90c3818992c98cb0",
            "d9cf5a6792aa4ad69f656f774513a17f",
            "553089f9ea2849fb8c351b5c9e0e63c4",
            "8b1546e7cbac42e1b17a749d8d3dc9fd",
            "aa7551ba54464a88afaa9d9f359d4143",
            "0a41fca1473843dda575cd64885497b7",
            "023d4f8e90994774a885b0ff57402d49",
            "5f5de52b73a24c3f833c973ab6ba3bb1",
            "b3bae6c9436047f8948f2ffe25ba9765",
            "d1a6b0d0bb5a45929e7971974a403fbd",
            "2effc5acb40c45ceb64c47088ece75e0",
            "a5ce97c40c3f4b7db745e9043aab26eb",
            "316d693eab7c495aa64a5512d90633fd",
            "860f153f375c4fdaab77153cd41de14d",
            "a711ce31651b481ba48866a865afb78c",
            "aaa39366823643b294f8dac67ac0bb3d",
            "e8536c20d69b4958b3a2c9403a3d4535",
            "6f3330b4b19a441c943c9249ad12172f",
            "aaca15d751cb4ef8a75ad2ee25718638",
            "1820a4698fcb4a0bb389404d40057399",
            "96d06bb1a908491fb6f540b057f2a42e",
            "b00ccba595694f2ea6eff464da8976c4",
            "d8e770468e964ad1942cf69591f2131c",
            "e96caa6b3edd444cabb0db8f078b0b85",
            "8a7e431c2be34e4aa263bcd7d9ca2681",
            "f37feae8d3fb4a27a80b19890e90cfd2"
          ]
        },
        "deepnote_cell_height": 1054.796875,
        "deepnote_cell_type": "code",
        "id": "wDM2KTPQm8V3",
        "outputId": "ca80d3c5-d10a-4559-d7a5-d618aeb155a9",
        "ExecuteTime": {
          "end_time": "2025-03-25T15:24:43.920385200Z",
          "start_time": "2025-03-25T15:24:30.235811Z"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743781958290,
          "user_tz": -120,
          "elapsed": 20883,
          "user": {
            "displayName": "Mateusz Budzyński",
            "userId": "05911681996609353404"
          }
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c67ad8b206004340992321304d25b6c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-46afbaa455d4>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  batch = [torch.tensor(t) for t in dataset[i]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa7551ba54464a88afaa9d9f359d4143"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaa39366823643b294f8dac67ac0bb3d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the data\n",
        "\n",
        "batch_size = 128\n",
        "data_path = \"./data\"\n",
        "\n",
        "transform = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "_test = torchvision.datasets.MNIST(\n",
        "    data_path, train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "# Load training data, split into train and valid sets\n",
        "_train = torchvision.datasets.MNIST(\n",
        "    data_path, train=True, download=True, transform=transform\n",
        ")\n",
        "_train.data = _train.data[:50000]\n",
        "_train.targets = _train.targets[:50000]\n",
        "\n",
        "_valid = torchvision.datasets.MNIST(\n",
        "    data_path, train=True, download=True, transform=transform\n",
        ")\n",
        "_valid.data = _valid.data[50000:]\n",
        "_valid.targets = _valid.targets[50000:]\n",
        "\n",
        "mnist_loaders = {\n",
        "    \"train\": InMemDataLoader(_train, batch_size=batch_size, shuffle=True),\n",
        "    \"valid\": InMemDataLoader(_valid, batch_size=batch_size, shuffle=False),\n",
        "    \"test\": InMemDataLoader(_test, batch_size=batch_size, shuffle=False),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "00024-481f7a8f-3abb-4f8f-aaba-951e8e06aafc",
        "deepnote_cell_height": 108.390625,
        "deepnote_cell_type": "markdown",
        "id": "rRYr7XmnnGO_"
      },
      "source": [
        "## SGD implementation\n",
        "\n",
        "We provide below a scaffolding for SGD. You will need to fill the TODOs while solving the assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "Ko_zq9i_CQkm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00025-2145e55b-7562-438c-bce3-8720962f9bfb",
        "deepnote_cell_height": 2460,
        "deepnote_cell_type": "code",
        "id": "WY1xG-cqnRoE",
        "ExecuteTime": {
          "end_time": "2025-03-25T15:24:43.982033100Z",
          "start_time": "2025-03-25T15:24:43.935385100Z"
        }
      },
      "outputs": [],
      "source": [
        "def SGD(\n",
        "    model,\n",
        "    data_loaders,\n",
        "    alpha=1e-4,\n",
        "    epsilon=0.99,\n",
        "    decay=0.0,\n",
        "    num_epochs=1,\n",
        "    max_num_epochs=np.nan,\n",
        "    patience_expansion=1.5,\n",
        "    log_every=100,\n",
        "    device=\"cpu\",\n",
        "):\n",
        "\n",
        "    # Put the model in train mode, and move to the evaluation device.\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    for data_loader in data_loaders.values():\n",
        "        if isinstance(data_loader, InMemDataLoader):\n",
        "            data_loader.to(device)\n",
        "\n",
        "    velocities = [torch.zeros_like(p) for p in model.parameters()]\n",
        "    iter_ = 0\n",
        "    epoch = 0\n",
        "    best_params = None\n",
        "    best_val_err = np.inf\n",
        "    history = {\"train_losses\": [], \"train_errs\": [], \"val_errs\": []}\n",
        "    print(\"Training the model!\")\n",
        "    print(\"Interrupt at any time to evaluate the best validation model so far.\")\n",
        "    try:\n",
        "        tstart = time.time()\n",
        "        siter = iter_\n",
        "        while epoch < num_epochs:\n",
        "            model.train()\n",
        "            epoch += 1\n",
        "            if epoch > max_num_epochs:\n",
        "                break\n",
        "\n",
        "            for x, y in data_loaders[\"train\"]:\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "                iter_ += 1\n",
        "                out = model(x)\n",
        "                loss = model.loss(out, y)\n",
        "                loss.backward()\n",
        "                _, predictions = out.max(dim=1)\n",
        "                batch_err_rate = (predictions != y).sum().item() / out.size(0)\n",
        "\n",
        "                history[\"train_losses\"].append(loss.item())\n",
        "                history[\"train_errs\"].append(batch_err_rate)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for (name, p), v in zip(model.named_parameters(), velocities):\n",
        "                        if \"weight\" in name:\n",
        "                            p.grad += decay * p # l2 regularization p a nie p**2 bo pochodna z p**2 to 2*p\n",
        "\n",
        "\n",
        "                        if iter_ == 10000 == 0:\n",
        "                            alpha = alpha * 0.5\n",
        "\n",
        "\n",
        "                        v[:] = epsilon * v + (1 - epsilon) * p.grad\n",
        "\n",
        "                        p -= alpha * v\n",
        "                        p.grad.zero_()\n",
        "\n",
        "                if iter_ % log_every == 0:\n",
        "                    num_iter = iter_ - siter + 1\n",
        "                    print(\n",
        "                        \"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%, steps/s {3: >5.2f}\".format(\n",
        "                            iter_,\n",
        "                            loss.item(),\n",
        "                            batch_err_rate * 100.0,\n",
        "                            num_iter / (time.time() - tstart),\n",
        "                        )\n",
        "                    )\n",
        "                    tstart = time.time()\n",
        "\n",
        "            val_err_rate = compute_error_rate(model, data_loaders[\"valid\"], device)\n",
        "            history[\"val_errs\"].append((iter_, val_err_rate))\n",
        "\n",
        "            if val_err_rate < best_val_err:\n",
        "                # Adjust num of epochs\n",
        "                num_epochs = int(np.maximum(num_epochs, epoch * patience_expansion + 1))\n",
        "                best_epoch = epoch\n",
        "                best_val_err = val_err_rate\n",
        "                best_params = [p.detach().cpu() for p in model.parameters()]\n",
        "            clear_output(True)\n",
        "            m = \"After epoch {0: >2} | valid err rate: {1: >5.2f}% | doing {2: >3} epochs\".format(\n",
        "                epoch, val_err_rate * 100.0, num_epochs\n",
        "            )\n",
        "            print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    if best_params is not None:\n",
        "        print(\"\\nLoading best params on validation set (epoch %d)\\n\" % (best_epoch))\n",
        "        with torch.no_grad():\n",
        "            for param, best_param in zip(model.parameters(), best_params):\n",
        "                param[...] = best_param\n",
        "    plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1"
      ],
      "metadata": {
        "id": "otk9fN17n53N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def loop_matrix_multiplication(A, B):\n",
        "    result = [[0 for _ in range(B.shape[1])] for _ in range(A.shape[0])]\n",
        "    for i in range(A.shape[0]):\n",
        "        for j in range(B.shape[1]):\n",
        "            for k in range(A.shape[1]):\n",
        "                result[i][j] += A[i, k] * B[k, j]\n",
        "    return result\n",
        "\n",
        "def np_einsum_matrix_multiplication(A, B):\n",
        "    return np.einsum(\"ik,kj->ij\", A, B)\n",
        "\n",
        "def np_matrix_multiplication_cpu(A, B):\n",
        "    return np.dot(A, B)\n",
        "\n",
        "def torch_matrix_multiplication_cpu(A, B):\n",
        "    A, B = torch.tensor(A, dtype=torch.float32), torch.tensor(B, dtype=torch.float32)\n",
        "    return torch.mm(A, B)\n",
        "\n",
        "def generate_random_matrix(n, m, max_value=10):\n",
        "    return np.random.randint(0, max_value, (n, m))\n",
        "\n",
        "def measure_time(matrix_multiplication_function, A, B):\n",
        "    start = time.time()\n",
        "    matrix_multiplication_function(A, B)\n",
        "    return time.time() - start\n",
        "\n",
        "def compare_matrix_multiplication_speeds(matrix_shapes, examples_per_case=5, time_limit=1.0):\n",
        "    functions = {\n",
        "        \"loop\": loop_matrix_multiplication,\n",
        "        \"einsum\": np_einsum_matrix_multiplication,\n",
        "        \"np_cpu\": np_matrix_multiplication_cpu,\n",
        "        \"torch_cpu\": torch_matrix_multiplication_cpu,\n",
        "    }\n",
        "\n",
        "    time_results = {key: [] for key in functions.keys()}\n",
        "\n",
        "    for shape in matrix_shapes:\n",
        "        print(f\"\\nTesting shape: {shape}\")\n",
        "        A = generate_random_matrix(shape[0], shape[1])\n",
        "        B = generate_random_matrix(shape[1], shape[0])\n",
        "\n",
        "        to_remove = []\n",
        "\n",
        "        for name, func in functions.items():\n",
        "            avg_time = 0\n",
        "            for _ in range(examples_per_case):\n",
        "                avg_time += measure_time(func, A, B)\n",
        "\n",
        "            avg_time /= examples_per_case\n",
        "            time_results[name].append(avg_time)\n",
        "\n",
        "            print(f\"  {name}: {avg_time:.4f} sec\")\n",
        "\n",
        "            if avg_time > time_limit:\n",
        "                print(f\"  -> Removing {name} (too slow)\")\n",
        "                to_remove.append(name)\n",
        "\n",
        "        for name in to_remove:\n",
        "            del functions[name]\n",
        "\n",
        "        if not functions:\n",
        "            print(\"No methods left to test. Stopping.\")\n",
        "            break\n",
        "\n",
        "    return time_results, matrix_shapes[:len(next(iter(time_results.values())))]\n",
        "\n",
        "matrix_shapes = [(50 + 10*i,50 + 10 * (i+1)) for i in range(50)]\n",
        "\n",
        "time_results, tested_shapes = compare_matrix_multiplication_speeds(matrix_shapes)\n",
        "\n",
        "\n",
        "def compare_transposed_matrix_multiplication_speeds(shape, examples_per_case=10):\n",
        "    A = np.random.randn(shape, shape)\n",
        "    B = np.random.randn(shape, shape)\n",
        "\n",
        "    functions = {\n",
        "        \"AB\": lambda A, B: torch_matrix_multiplication_cpu(A, B),\n",
        "        \"A^T B\": lambda A, B: torch_matrix_multiplication_cpu(A.T, B),\n",
        "        \"A B^T\": lambda A, B: torch_matrix_multiplication_cpu(A, B.T),\n",
        "        \"A^T B^T\": lambda A, B: torch_matrix_multiplication_cpu(A.T, B.T)\n",
        "    }\n",
        "\n",
        "    times = {key: 0 for key in functions.keys()}\n",
        "\n",
        "    for _ in range(examples_per_case):\n",
        "        for key, func in functions.items():\n",
        "            times[key] += measure_time(func, A, B)\n",
        "\n",
        "    for key in times:\n",
        "        times[key] /= examples_per_case\n",
        "\n",
        "    return times\n",
        "\n",
        "time_results = compare_transposed_matrix_multiplication_speeds(2000)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(time_results.keys(), time_results.values(), color=['blue', 'orange', 'green', 'red'])\n",
        "plt.xlabel(\"Multiplication Type\")\n",
        "plt.ylabel(\"Time (seconds)\")\n",
        "plt.title(\"Comparison of Different Matrix Multiplication Types on CPU\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iwLQGSAin3qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem 2"
      ],
      "metadata": {
        "id": "_0he5_sjnzWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00026-06863917-ddb1-425f-9d6e-93c06b30e87b",
        "deepnote_cell_height": 1464.5625,
        "deepnote_cell_type": "code",
        "deepnote_output_heights": [
          null,
          249.5,
          251.078125
        ],
        "id": "2gmDmR2K6CVQ"
      },
      "outputs": [],
      "source": [
        "# class Model(nn.Module):\n",
        "#     def __init__(self, *args, **kwargs):\n",
        "#         super(Model, self).__init__()\n",
        "#         self.layers = nn.Sequential(*args, **kwargs)\n",
        "\n",
        "#     def forward(self, X):\n",
        "#         X = X.view(X.size(0), -1)\n",
        "#         return self.layers.forward(X)\n",
        "\n",
        "#     def loss(self, Out, Targets):\n",
        "#         return F.cross_entropy(Out, Targets)\n",
        "\n",
        "\n",
        "# # model = Model(nn.Linear(28 * 28, 10))\n",
        "\n",
        "# # with torch.no_grad():\n",
        "# #     # Initialize parameters\n",
        "# #     for name, p in model.named_parameters():\n",
        "# #         if \"weight\" in name:\n",
        "# #             torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "# #         elif \"bias\" in name:\n",
        "# #             p.zero_()\n",
        "# #         else:\n",
        "# #             raise ValueError('Unknown parameter name \"%s\"' % name)\n",
        "\n",
        "# # # On GPU enabled devices set device='cuda' else set device='cpu'\n",
        "# # t_start = time.time()\n",
        "# # SGD(model, mnist_loaders, alpha=1e-1, max_num_epochs=30, device=\"cuda\")\n",
        "\n",
        "\n",
        "# # test_err_rate = compute_error_rate(model, mnist_loaders[\"test\"])\n",
        "# # m = (\n",
        "# #     f\"Test error rate: {test_err_rate * 100.0:.3f}%, \"\n",
        "# #     f\"training took {time.time() - t_start:.0f}s.\"\n",
        "# # )\n",
        "# # print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3"
      ],
      "metadata": {
        "collapsed": false,
        "id": "yWKpDVPRCQkm"
      }
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "model = Model(nn.Linear(28 * 28, 3136),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(3136, 1568),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(1568,392),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(392,10))\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Initialize parameters\n",
        "    for name, p in model.named_parameters():\n",
        "        if \"weight\" in name:\n",
        "            torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "        elif \"bias\" in name:\n",
        "            p.zero_()\n",
        "        else:\n",
        "            raise ValueError('Unknown parameter name \"%s\"' % name)\n",
        "\n",
        "# On GPU enabled devices set device='cuda' else set device='cpu'\n",
        "t_start = time.time()\n",
        "SGD(model, mnist_loaders, alpha=0.01, max_num_epochs=100, device=\"cuda\")\n",
        "\n",
        "\n",
        "test_err_rate = compute_error_rate(model, mnist_loaders[\"test\"])\n",
        "m = (\n",
        "    f\"Test error rate: {test_err_rate * 100.0:.3f}%, \"\n",
        "    f\"training took {time.time() - t_start:.0f}s.\"\n",
        ")\n",
        "print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))"
      ],
      "metadata": {
        "id": "K5r5wiCBCQkn"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "l2Xa1yFaCQkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 4"
      ],
      "metadata": {
        "id": "MsLdKleRmfPr"
      }
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class Model2(nn.Module):\n",
        "    def __init__(self, *layers):\n",
        "        super(Model2, self).__init__()\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.layers(X)\n",
        "\n",
        "    def loss(self, out, targets):\n",
        "        return F.cross_entropy(out, targets)\n",
        "\n",
        "\n",
        "model = Model2(\n",
        "\n",
        "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64 * 7 * 7, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 10)\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for name, p in model.named_parameters():\n",
        "        if \"weight\" in name:\n",
        "            p.normal_(0, 0.2)\n",
        "        elif \"bias\" in name:\n",
        "            p.zero_()\n",
        "        else:\n",
        "            raise ValueError('Unknown parameter name \"%s\"' % name)\n",
        "\n",
        "t_start = time.time()\n",
        "SGD(model, mnist_loaders, alpha=0.01, max_num_epochs=50, device=\"cuda\")\n",
        "\n",
        "\n",
        "test_err_rate = compute_error_rate(model, mnist_loaders[\"test\"])\n",
        "m = (\n",
        "    f\"Test error rate: {test_err_rate * 100.0:.3f}%, \"\n",
        "    f\"training took {time.time() - t_start:.0f}s.\"\n",
        ")\n",
        "print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))"
      ],
      "metadata": {
        "id": "-RIIMPZOCQkn"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem 5"
      ],
      "metadata": {
        "id": "55GGqeTAXdO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "    transforms.RandomErasing(p=0.2),\n",
        "])\n",
        "\n",
        "mnist_loaders = {\n",
        "    \"train\": InMemDataLoader(_train, batch_size=batch_size, shuffle=True, transform = train_transform),\n",
        "    \"valid\": InMemDataLoader(_valid, batch_size=batch_size, shuffle=False),\n",
        "    \"test\": InMemDataLoader(_test, batch_size=batch_size, shuffle=False),\n",
        "}\n",
        "\n",
        "model4 = Model(nn.Linear(28 * 28, 3136),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(3136, 1568),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(1568,392),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(392,10))\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Initialize parameters\n",
        "    for name, p in model4.named_parameters():\n",
        "        if \"weight\" in name:\n",
        "            torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "        elif \"bias\" in name:\n",
        "            p.zero_()\n",
        "        else:\n",
        "            raise ValueError('Unknown parameter name \"%s\"' % name)\n",
        "\n",
        "t_start = time.time()\n",
        "SGD(model4, mnist_loaders, alpha=0.01, max_num_epochs=100, device=\"cuda\")\n",
        "\n",
        "\n",
        "test_err_rate = compute_error_rate(model4, mnist_loaders[\"test\"])\n",
        "m = (\n",
        "    f\"Test error rate: {test_err_rate * 100.0:.3f}%, \"\n",
        "    f\"training took {time.time() - t_start:.0f}s.\"\n",
        ")\n",
        "print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))\n"
      ],
      "metadata": {
        "id": "xCoSnau0ZHKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 6 [2p]"
      ],
      "metadata": {
        "collapsed": false,
        "id": "LRDSdy6RCQkn"
      }
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "\n",
        "model = Model(nn.Linear(28 * 28, 3136),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.1),\n",
        "              nn.Linear(3136, 1568),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.2),\n",
        "              nn.Linear(1568,392),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.1),\n",
        "              nn.Linear(392,10))\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Initialize parameters\n",
        "    for name, p in model.named_parameters():\n",
        "        if \"weight\" in name:\n",
        "            torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "        elif \"bias\" in name:\n",
        "            p.zero_()\n",
        "        else:\n",
        "            raise ValueError('Unknown parameter name \"%s\"' % name)\n",
        "\n",
        "t_start = time.time()\n",
        "SGD(model, mnist_loaders, alpha=1e-1, max_num_epochs=50, device=\"cuda\")\n",
        "\n",
        "\n",
        "test_err_rate = compute_error_rate(model, mnist_loaders[\"test\"])\n",
        "m = (\n",
        "    f\"Test error rate: {test_err_rate * 100.0:.3f}%, \"\n",
        "    f\"training took {time.time() - t_start:.0f}s.\"\n",
        ")\n",
        "print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))"
      ],
      "metadata": {
        "is_executing": true,
        "id": "uYPsJEaACQkn"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zadanie 7"
      ],
      "metadata": {
        "id": "sl-6louGjhPf"
      }
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "\n",
        "class MyBatchNorm(nn.Module):\n",
        "    def __init__(self, num_features, epsilon=1e-5, momentum=0.1):\n",
        "        super(MyBatchNorm, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
        "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
        "\n",
        "        self.register_buffer(\"running_mean\", torch.zeros(num_features))\n",
        "        self.register_buffer(\"running_var\", torch.ones(num_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            batch_mean = x.mean(dim=0)\n",
        "            batch_var = x.var(dim=0, unbiased=False)\n",
        "\n",
        "            self.running_mean = self.running_mean.to(x.device)\n",
        "            self.running_var = self.running_var.to(x.device)\n",
        "\n",
        "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * batch_mean\n",
        "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * batch_var\n",
        "\n",
        "            x_norm = (x - batch_mean) / torch.sqrt(batch_var + self.epsilon)\n",
        "        else:\n",
        "            x_norm = (x - self.running_mean) / torch.sqrt(self.running_var + self.epsilon)\n",
        "\n",
        "        return self.gamma * x_norm + self.beta\n",
        "\n"
      ],
      "metadata": {
        "is_executing": true,
        "id": "ytIolRiYCQkn"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Model(nn.Linear(28 * 28, 3136),\n",
        "#               MyBatchNorm(3136),\n",
        "#               nn.ReLU(),\n",
        "#               nn.Linear(3136, 1568),\n",
        "#               MyBatchNorm(1568),\n",
        "#               nn.ReLU(),\n",
        "#               nn.Linear(1568,392),\n",
        "#               MyBatchNorm(392),\n",
        "#               nn.ReLU(),\n",
        "#               nn.Linear(392,10))\n",
        "\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     # Initialize parameters\n",
        "#     for name, p in model.named_parameters():\n",
        "#         if \"weight\" in name:\n",
        "#             torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "#         elif \"bias\" in name:\n",
        "#             p.zero_()\n",
        "#         else:\n",
        "#            pass\n",
        "#             # raise ValueError('Unknown parameter name \"%s\"' % name)\n",
        "\n",
        "# t_start = time.time()\n",
        "# SGD(model, mnist_loaders, alpha=1e-1, max_num_epochs=30, device=\"cuda\")\n",
        "\n",
        "\n",
        "# test_err_rate = compute_error_rate(model, mnist_loaders[\"test\"])\n",
        "# m = (\n",
        "#     f\"Test error rate: {test_err_rate * 100.0:.3f}%, \"\n",
        "#     f\"training took {time.time() - t_start:.0f}s.\"\n",
        "# )\n",
        "# print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))"
      ],
      "metadata": {
        "id": "_J3hh_v2lR3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zadanie 9"
      ],
      "metadata": {
        "id": "dfikM_o8OFWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import error\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "\n",
        "\n",
        "\n",
        "alpha_values = [i * 0.001 for i in range(1, 20)]\n",
        "decay_values = [0]\n",
        "neurons_values = [500 + i * 100 for i in range(20)]\n",
        "epsilon_values = [0.95 + i * 0.01 for i in range(6)]\n",
        "\n",
        "def get_random_from_table(table):\n",
        "    return random.choice(table)\n",
        "\n",
        "def get_random_model():\n",
        "    layers = [get_random_from_table(neurons_values) for _ in range(3)]\n",
        "    layers.sort(reverse=True)\n",
        "    model = Model(\n",
        "        nn.Linear(28 * 28, layers[0]),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(layers[0], layers[1]),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(layers[1], layers[2]),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(layers[2], 10)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def initialize_model(model):\n",
        "    with torch.no_grad():\n",
        "        for name, p in model.named_parameters():\n",
        "            if \"weight\" in name:\n",
        "                torch.nn.init.kaiming_normal_(p, mode='fan_in', nonlinearity='relu')\n",
        "            elif \"bias\" in name:\n",
        "                p.zero_()\n",
        "\n",
        "RUNS_NUMBER = 100\n",
        "error_rates_with_hiperparameters = {}\n",
        "\n",
        "def tune_hiperparameters(runs=RUNS_NUMBER):\n",
        "    for i in range(runs):\n",
        "        print(f\"\\n===== Run {i+1}/{runs} =====\")\n",
        "        model = get_random_model()\n",
        "        initialize_model(model)\n",
        "\n",
        "        alpha = get_random_from_table(alpha_values)\n",
        "        decay = get_random_from_table(decay_values)\n",
        "        epsilon = get_random_from_table(epsilon_values)\n",
        "\n",
        "        wandb.init(\n",
        "            project=\"hyperparameter_tuning\",\n",
        "            config={\n",
        "                \"alpha\": alpha,\n",
        "                \"epsilon\": epsilon,\n",
        "                \"max_num_epochs\": 70,\n",
        "                \"device\": \"cuda\"\n",
        "            },\n",
        "            reinit=True\n",
        "        )\n",
        "\n",
        "        print(f\"Hyperparameters: alpha={alpha}, decay={decay}, epsilon={epsilon}\")\n",
        "\n",
        "        print(f\"Hyperparameters: alpha={alpha}, decay={decay}, epsilon={epsilon}\")\n",
        "\n",
        "        t_start = time.time()\n",
        "        SGD(model, mnist_loaders, alpha=alpha, max_num_epochs=70, device=\"cuda\", decay=0, epsilon=epsilon)\n",
        "        elapsed = time.time() - t_start\n",
        "\n",
        "        test_err_rate = compute_error_rate(model, mnist_loaders[\"test\"])\n",
        "        print(f\"Run {i+1} zakończony: czas treningu: {elapsed:.0f}s, błąd testowy: {test_err_rate*100:.2f}%\")\n",
        "\n",
        "        wandb.log({\n",
        "              \"elapsed_time\": elapsed,\n",
        "              \"test_error_rate\": test_err_rate,\n",
        "              \"alpha\": alpha,\n",
        "              \"epsilon\": epsilon,\n",
        "          })\n",
        "        wandb.finish()\n",
        "\n",
        "        config_key = f\"alpha: {alpha}, decay: {decay}, epsilon: {epsilon}\"\n",
        "        error_rates_with_hiperparameters[config_key] = test_err_rate\n",
        "\n",
        "    best_config = min(error_rates_with_hiperparameters, key=error_rates_with_hiperparameters.get)\n",
        "    best_error = error_rates_with_hiperparameters[best_config]\n",
        "\n",
        "    print(\"\\n===== Podsumowanie =====\")\n",
        "    print(f\"Best Config: {best_config}\")\n",
        "    print(f\"Best error: {best_error*100:.2f}%\")\n",
        "\n",
        "    return error_rates_with_hiperparameters\n",
        "\n",
        "results = tune_hiperparameters(RUNS_NUMBER)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "4rZHh472OOYq",
        "executionInfo": {
          "status": "error",
          "timestamp": 1743785116805,
          "user_tz": -120,
          "elapsed": 369304,
          "user": {
            "displayName": "Mateusz Budzyński",
            "userId": "05911681996609353404"
          }
        },
        "outputId": "7bb9980b-4fa1-4569-f205-a99ad2a0703b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------\n",
            "After epoch 21 | valid err rate:  2.74% | doing  32 epochs\n",
            "----------------------------------------------------------\n",
            "Minibatch   8300  | loss  0.28 | err rate  7.81%, steps/s 12351.11\n",
            "Minibatch   8400  | loss  0.15 | err rate  3.91%, steps/s 13983.87\n",
            "\n",
            "Loading best params on validation set (epoch 21)\n",
            "\n",
            "Run 4 zakończony: czas treningu: 48s, błąd testowy: 2.85%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>alpha</td><td>▁</td></tr><tr><td>elapsed_time</td><td>▁</td></tr><tr><td>epsilon</td><td>▁</td></tr><tr><td>test_error_rate</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>alpha</td><td>0.006</td></tr><tr><td>elapsed_time</td><td>47.61094</td></tr><tr><td>epsilon</td><td>0.99</td></tr><tr><td>test_error_rate</td><td>0.0285</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">crisp-energy-58</strong> at: <a href='https://wandb.ai/budzynekm09-uniwersytet-wroc-awski/hyperparameter_tuning/runs/qj9rjckc' target=\"_blank\">https://wandb.ai/budzynekm09-uniwersytet-wroc-awski/hyperparameter_tuning/runs/qj9rjckc</a><br> View project at: <a href='https://wandb.ai/budzynekm09-uniwersytet-wroc-awski/hyperparameter_tuning' target=\"_blank\">https://wandb.ai/budzynekm09-uniwersytet-wroc-awski/hyperparameter_tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250404_164418-qj9rjckc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Run 5/100 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250404_164510-o4hyh094</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/budzynekm09-uniwersytet-wroc-awski/hyperparameter_tuning/runs/o4hyh094' target=\"_blank\">daily-brook-59</a></strong> to <a href='https://wandb.ai/budzynekm09-uniwersytet-wroc-awski/hyperparameter_tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/budzynekm09-uniwersytet-wroc-awski/hyperparameter_tuning' target=\"_blank\">https://wandb.ai/budzynekm09-uniwersytet-wroc-awski/hyperparameter_tuning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/budzynekm09-uniwersytet-wroc-awski/hyperparameter_tuning/runs/o4hyh094' target=\"_blank\">https://wandb.ai/budzynekm09-uniwersytet-wroc-awski/hyperparameter_tuning/runs/o4hyh094</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: alpha=0.009000000000000001, decay=0, epsilon=0.97\n",
            "Hyperparameters: alpha=0.009000000000000001, decay=0, epsilon=0.97\n",
            "Training the model!\n",
            "Interrupt at any time to evaluate the best validation model so far.\n",
            "Minibatch    100  | loss  1.04 | err rate 28.12%, steps/s 180.31\n",
            "Minibatch    200  | loss  0.57 | err rate 15.62%, steps/s 392.79\n",
            "Minibatch    300  | loss  0.57 | err rate 16.41%, steps/s 585.48\n",
            "\n",
            "Loading best params on validation set (epoch 1)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5aba17ad2610>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_rates_with_hiperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune_hiperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRUNS_NUMBER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-5aba17ad2610>\u001b[0m in \u001b[0;36mtune_hiperparameters\u001b[0;34m(runs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtest_err_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_error_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Run {i+1} zakończony: czas treningu: {elapsed:.0f}s, błąd testowy: {test_err_rate*100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-92ae65002f32>\u001b[0m in \u001b[0;36mcompute_error_rate\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnum_errs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6df151b99396>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <function flush_figures at 0x7846ac554360> (for post_execute):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             display(\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2182\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2185\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                 \"bbox_inches_restore\"}\n\u001b[1;32m   2039\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptional_kws\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m             print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n\u001b[0m\u001b[1;32m   2041\u001b[0m                 *args, **{k: v for k, v in kwargs.items() if k not in skip}))\n\u001b[1;32m   2042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Let third-parties do as they see fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \"\"\"\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_pil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \"\"\"\n\u001b[1;32m    429\u001b[0m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         mpl.image.imsave(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2596\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2598\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         )\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msingle_im\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m         ImageFile._save(\n\u001b[0m\u001b[1;32m   1489\u001b[0m             \u001b[0msingle_im\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flush\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    582\u001b[0m                     \u001b[0;31m# compress to Python file-compatible object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                         \u001b[0merrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m                         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "ffaf5b3e-ad2e-45f4-b61f-77edfc82388b",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}